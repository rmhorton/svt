{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f736155-d85e-4a08-b10d-ce3920312586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "featurized_data_file = 'IMDB_sentiment.parquet' # 'sentiment_data_categories_featurized.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "524c144c-e849-4dd3-bedf-f9dd1e7f595f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>vector</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.030099309980869293, 0.050417669117450714, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.012201860547065735, 0.05196147784590721, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.014258158393204212, -0.0791383758187294, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.041720371693372726, 0.010464085265994072, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.03167529031634331, 0.00642420444637537, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                              vector  binary_label  \n",
       "0  [0.030099309980869293, 0.050417669117450714, -...             1  \n",
       "1  [-0.012201860547065735, 0.05196147784590721, -...             1  \n",
       "2  [0.014258158393204212, -0.0791383758187294, 0....             1  \n",
       "3  [-0.041720371693372726, 0.010464085265994072, ...             0  \n",
       "4  [-0.03167529031634331, 0.00642420444637537, -0...             1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = pd.read_parquet(featurized_data_file)\n",
    "text_df.columns = ['text', 'label', 'vector']\n",
    "text_df['binary_label'] = [ 1 if x=='positive' else 0 for x in text_df['label']]\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8688624d-4189-4aba-be1c-fee7031a35eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9003717999999999"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_clf = LogisticRegressionCV(cv=5, scoring='roc_auc',\n",
    "                                     n_jobs=-1, max_iter=10000)\n",
    "X_emb = [v for v in text_df['vector']]\n",
    "y = text_df['binary_label']\n",
    "sentiment_clf.fit(X_emb, y)\n",
    "\n",
    "get_mean_xval_score_for_binary_classifier = lambda clf: np.mean([np.max(v) for v in clf.scores_[clf.classes_[1]]])\n",
    "get_mean_xval_score_for_binary_classifier(sentiment_clf)  # 0.8182599999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "414bb674-46b0-4bf8-a8be-57da1346b342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9046707968000001"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat0 = sentiment_clf.predict_proba(X_emb)[:,1]\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_hat0)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43ffcc12-28b0-48bd-928f-99a9493212d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the cases by weighted semantic embedding and predict the clusters\n",
    "\n",
    "to_unit_vector = lambda v: np.array(v/np.sqrt(np.sum(v*v)))\n",
    "\n",
    "unit_coef_vector = to_unit_vector(sentiment_clf.coef_)[0]  # ???\n",
    "\n",
    "X_weighted = np.array([ unit_coef_vector * v for v in text_df['vector']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c289c202-4ffd-42bb-a4f2-1421694271f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9046707968000001"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['score2'] = [np.sum(v) for v in X_weighted]\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(text_df['binary_label'], text_df['score2'])\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b84f4bfa-ff30-4290-a732-100cf18332f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.600041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.378049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.552006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.751390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         binary_label\n",
       "cluster              \n",
       "0            0.600041\n",
       "1            0.378049\n",
       "2            0.269825\n",
       "3            0.552006\n",
       "4            0.751390"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "k = 5\n",
    "kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\").fit(X_weighted)\n",
    "# Counter(kmeans.labels_)\n",
    "\n",
    "text_df['cluster'] = kmeans.labels_\n",
    "text_df.groupby('cluster').agg({'binary_label': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f93ba8-ad4e-46a7-8ad1-91609cdbc4aa",
   "metadata": {},
   "source": [
    "Now make 2k separate categories for the positive and negative cases within each cluster, and predict those with a multinomial classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4b148900-63e2-4ed1-bf16-286586c12d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>vector</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>cluster</th>\n",
       "      <th>score2</th>\n",
       "      <th>ccat_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.030099309980869293, 0.050417669117450714, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.008220</td>\n",
       "      <td>c0s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.012201860547065735, 0.05196147784590721, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.025556</td>\n",
       "      <td>c4s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.014258158393204212, -0.0791383758187294, 0....</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.017175</td>\n",
       "      <td>c3s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.041720371693372726, 0.010464085265994072, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.068911</td>\n",
       "      <td>c1s0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.03167529031634331, 0.00642420444637537, -0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.087525</td>\n",
       "      <td>c0s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.031536709517240524, -0.06321507692337036, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>c2s1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.04839408025145531, -0.08552412688732147, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.132043</td>\n",
       "      <td>c4s0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.03935423120856285, -0.002203170442953706, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.066901</td>\n",
       "      <td>c4s0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.01833348162472248, -0.026902485638856888, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.040115</td>\n",
       "      <td>c0s0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.03784305974841118, -0.06780193001031876, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.042920</td>\n",
       "      <td>c3s0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  \\\n",
       "0      One of the other reviewers has mentioned that ...  positive   \n",
       "1      A wonderful little production. <br /><br />The...  positive   \n",
       "2      I thought this was a wonderful way to spend ti...  positive   \n",
       "3      Basically there's a family where a little boy ...  negative   \n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "...                                                  ...       ...   \n",
       "49995  I thought this movie did a down right good job...  positive   \n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
       "49997  I am a Catholic taught in parochial elementary...  negative   \n",
       "49998  I'm going to have to disagree with the previou...  negative   \n",
       "49999  No one expects the Star Trek movies to be high...  negative   \n",
       "\n",
       "                                                  vector  binary_label  \\\n",
       "0      [0.030099309980869293, 0.050417669117450714, -...             1   \n",
       "1      [-0.012201860547065735, 0.05196147784590721, -...             1   \n",
       "2      [0.014258158393204212, -0.0791383758187294, 0....             1   \n",
       "3      [-0.041720371693372726, 0.010464085265994072, ...             0   \n",
       "4      [-0.03167529031634331, 0.00642420444637537, -0...             1   \n",
       "...                                                  ...           ...   \n",
       "49995  [-0.031536709517240524, -0.06321507692337036, ...             1   \n",
       "49996  [-0.04839408025145531, -0.08552412688732147, 0...             0   \n",
       "49997  [-0.03935423120856285, -0.002203170442953706, ...             0   \n",
       "49998  [-0.01833348162472248, -0.026902485638856888, ...             0   \n",
       "49999  [-0.03784305974841118, -0.06780193001031876, 0...             0   \n",
       "\n",
       "       cluster    score2 ccat_label  \n",
       "0            0 -0.008220       c0s1  \n",
       "1            4  0.025556       c4s1  \n",
       "2            3 -0.017175       c3s1  \n",
       "3            1 -0.068911       c1s0  \n",
       "4            0  0.087525       c0s1  \n",
       "...        ...       ...        ...  \n",
       "49995        2  0.028319       c2s1  \n",
       "49996        4 -0.132043       c4s0  \n",
       "49997        4 -0.066901       c4s0  \n",
       "49998        0 -0.040115       c0s0  \n",
       "49999        3 -0.042920       c3s0  \n",
       "\n",
       "[50000 rows x 7 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df['ccat_label'] = ['c' + str(row['cluster']) + 's' + str(row['binary_label']) for row in text_df.to_dict(orient='records')]\n",
    "\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "00e3931d-b664-4b18-b47a-661a6900f48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.46758681, -0.3262191 , -0.54736983, ..., -0.78718889,\n",
       "        -0.8240993 , -2.30844094],\n",
       "       [ 0.7263078 ,  0.48106036, -4.93787748, ..., -1.15162691,\n",
       "         0.16843801,  2.4044313 ],\n",
       "       [ 2.55087747,  0.47964774, -0.48959666, ...,  0.75008499,\n",
       "        -0.16324275, -0.81952582],\n",
       "       ...,\n",
       "       [-1.70562752, -0.46141821, -0.78334267, ...,  0.1632658 ,\n",
       "        -0.4218756 , -0.3679713 ],\n",
       "       [ 3.02415178, -1.28114591, -1.80577395, ..., -0.41676819,\n",
       "        -0.7781784 , -0.38803837],\n",
       "       [-2.71508513, -0.55943649, -3.08604026, ...,  0.89775432,\n",
       "        -1.9236693 , -0.37443604]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# category_clf = LogisticRegressionCV(cv=5, scoring='roc_auc', n_jobs=-1, max_iter=10000, multi_class='ovr', solver='lbfgs') #multinomial , solver='lbfgs'\n",
    "# category_clf.fit(X_emb, text_df['ccat_label'])\n",
    "\n",
    "# category_clf.coef_.shape # (10, 384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "58446067-5bc6-49b2-8506-65007bd4bcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 384)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_clf = LogisticRegressionCV(cv=5, \n",
    "                                    # scoring='roc_auc',  # not for multinomial\n",
    "                                    multi_class='multinomial', \n",
    "                                    # solver='lbfgs',\n",
    "                                    n_jobs=-1, max_iter=10000) \n",
    "\n",
    "category_clf.fit(X_emb, text_df['ccat_label']) # category_clf.coef_.shape # (10, 384)\n",
    "\n",
    "pprob = category_clf.predict_proba(X_emb) # pprob.shape # (50000, 10)\n",
    "pos_idx = np.where([int(cc[-1]) for cc in category_clf.classes_])\n",
    "best_pos_score = [np.max(v) for v in pprob[:, pos_idx][:,0,:] ] # where did the middle dimension come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "841a0e82-74d5-4f5c-9a02-250f9ad94f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_df = pd.DataFrame({'actual': text_df['ccat_label'],\n",
    "                      'predicted': category_clf.predict(X_emb)})\n",
    "\n",
    "pa_df['is_correct'] = [row['actual'] == row['predicted'] for row in pa_df.to_dict(orient='records')]\n",
    "\n",
    "ctr = Counter(pa_df['is_correct'])\n",
    "accuracy = ctr[True]/len(pa_df)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872ff0dc-3b4c-40e8-8dbb-bb0f6dd6ecc3",
   "metadata": {},
   "source": [
    "# LogisticRegressionSubCat Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bcf9b1b7-b2fc-4232-aa78-f60327108eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more detailed implementation, see https://medium.com/@hardik.prabhu/object-oriented-programming-and-ml-model-development-in-python-ada4bf76529b\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "class LogisticRegressionSubCat():\n",
    "    \"\"\" \n",
    "    A SubCategory ensemble classifier model based on LogisticRegressionCV.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k=5):\n",
    "        self.k = k\n",
    "        self.clf0 = LogisticRegressionCV(cv=5, n_jobs=-1, max_iter=10000)\n",
    "        self.kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\")\n",
    "        self.category_clf = LogisticRegressionCV(cv=5, multi_class='multinomial', n_jobs=-1, max_iter=10000) \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X is a 2D numpy array\n",
    "        \"\"\"\n",
    "        self.clf0.fit(X, y)\n",
    "        to_unit_vector = lambda v: np.array(v/np.sqrt(np.sum(v*v)))\n",
    "        unit_coef_vector = to_unit_vector(self.clf0.coef_)[0] # ???\n",
    "        X_weighted = np.array([ unit_coef_vector * v for v in X])\n",
    "        self.kmeans.fit(X_weighted)\n",
    "        self.ccat_label = [f\"c{clust:02d}_{lbl}\" for clust, lbl in zip(self.kmeans.labels_, y)]\n",
    "\n",
    "        self.category_clf.fit(X, self.ccat_label)\n",
    "\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Returns the best score for any cluster.\n",
    "        \"\"\"\n",
    "        pprob = category_clf.predict_proba(X)\n",
    "        pos_idx = np.where([int(cc[-1]) for cc in self.category_clf.classes_])\n",
    "        best_pos_score = [np.max(v) for v in pprob[:, pos_idx][:,0,:] ] # !!!??? where did the middle dimension come from?\n",
    "        return best_pos_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "49bb3981-c546-485c-a947-aa1b75309568",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for axis 1 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m lrsc \u001b[38;5;241m=\u001b[39m LogisticRegressionSubCat(k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m      5\u001b[0m lrsc\u001b[38;5;241m.\u001b[39mfit(X_emb, y)\n\u001b[1;32m----> 6\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mlrsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_emb\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# !!! This is just a test; try it on a held-out test set\u001b[39;00m\n\u001b[0;32m      8\u001b[0m fpr, tpr, thresholds \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mroc_curve(y, y_hat)\n\u001b[0;32m      9\u001b[0m metrics\u001b[38;5;241m.\u001b[39mauc(fpr, tpr) \u001b[38;5;66;03m# k=1: 0.6261, k=2: 0.5645, k=3:0.5626, k=4: 0.6513, k=5:0.9158, k=6, 8 or 10 fails (index out of bounds)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[156], line 41\u001b[0m, in \u001b[0;36mLogisticRegressionSubCat.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     39\u001b[0m pprob \u001b[38;5;241m=\u001b[39m category_clf\u001b[38;5;241m.\u001b[39mpredict_proba(X)\n\u001b[0;32m     40\u001b[0m pos_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere([\u001b[38;5;28mint\u001b[39m(cc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m cc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory_clf\u001b[38;5;241m.\u001b[39mclasses_])\n\u001b[1;32m---> 41\u001b[0m best_pos_score \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mmax(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpprob\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_idx\u001b[49m\u001b[43m]\u001b[49m[:,\u001b[38;5;241m0\u001b[39m,:] ] \u001b[38;5;66;03m# !!!??? where did the middle dimension come from?\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_pos_score\n",
      "\u001b[1;31mIndexError\u001b[0m: index 11 is out of bounds for axis 1 with size 10"
     ]
    }
   ],
   "source": [
    "X_emb = [v for v in text_df['vector']]\n",
    "y = text_df['binary_label']\n",
    "\n",
    "lrsc = LogisticRegressionSubCat(k=6)\n",
    "lrsc.fit(X_emb, y)\n",
    "y_hat = lrsc.predict_proba(X_emb) # !!! This is just a test; now try it on a held-out test set\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, y_hat)\n",
    "metrics.auc(fpr, tpr) # k=1: 0.6261, k=2: 0.5645, k=3:0.5626, k=4: 0.6513, k=5:0.9158, k=6, 8 or 10 fails (index out of bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "005ca7a9-f647-456a-bd90-7a583defddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c04_1',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c03_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_0',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c02_1',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c03_1',\n",
       " 'c01_1',\n",
       " 'c00_0',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c00_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c05_1',\n",
       " 'c01_0',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c00_0',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c02_1',\n",
       " 'c04_0',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c02_1',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c02_1',\n",
       " 'c03_0',\n",
       " 'c05_1',\n",
       " 'c03_1',\n",
       " 'c00_0',\n",
       " 'c04_1',\n",
       " 'c05_1',\n",
       " 'c03_0',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c00_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c01_1',\n",
       " 'c00_0',\n",
       " 'c01_0',\n",
       " 'c04_0',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c01_1',\n",
       " 'c02_1',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c03_0',\n",
       " 'c03_1',\n",
       " 'c01_0',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c01_0',\n",
       " 'c01_0',\n",
       " 'c04_1',\n",
       " 'c03_0',\n",
       " 'c00_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c00_0',\n",
       " 'c05_1',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c00_0',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c00_0',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c02_1',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c01_1',\n",
       " 'c03_1',\n",
       " 'c01_1',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c03_0',\n",
       " 'c00_0',\n",
       " 'c03_1',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c03_0',\n",
       " 'c03_1',\n",
       " 'c00_0',\n",
       " 'c01_1',\n",
       " 'c02_1',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c01_1',\n",
       " 'c00_0',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c01_1',\n",
       " 'c01_0',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c03_1',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c01_0',\n",
       " 'c04_0',\n",
       " 'c03_0',\n",
       " 'c02_1',\n",
       " 'c03_1',\n",
       " 'c03_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c01_0',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c02_1',\n",
       " 'c01_0',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c00_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_0',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c02_1',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c03_1',\n",
       " 'c03_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c00_1',\n",
       " 'c01_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c02_1',\n",
       " 'c05_0',\n",
       " 'c00_0',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c00_0',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c05_1',\n",
       " 'c01_1',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c02_1',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c04_0',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c03_0',\n",
       " 'c03_1',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c00_0',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c00_0',\n",
       " 'c05_0',\n",
       " 'c02_1',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c00_0',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c02_1',\n",
       " 'c01_0',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c01_0',\n",
       " 'c02_1',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c04_0',\n",
       " 'c00_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c03_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c03_0',\n",
       " 'c04_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c01_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c03_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c04_0',\n",
       " 'c01_1',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c03_0',\n",
       " 'c00_0',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c05_1',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c03_0',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c03_0',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c01_1',\n",
       " 'c00_0',\n",
       " 'c02_0',\n",
       " 'c00_0',\n",
       " 'c05_1',\n",
       " 'c02_1',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c01_0',\n",
       " 'c01_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c03_1',\n",
       " 'c01_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c01_0',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c00_0',\n",
       " 'c01_0',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c03_0',\n",
       " 'c05_1',\n",
       " 'c04_0',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c00_0',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c04_1',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c03_0',\n",
       " 'c01_0',\n",
       " 'c02_1',\n",
       " 'c00_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c03_0',\n",
       " 'c05_1',\n",
       " 'c03_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c01_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c01_1',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c01_0',\n",
       " 'c03_0',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c02_1',\n",
       " 'c05_1',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c01_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c01_1',\n",
       " 'c02_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c03_0',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c03_1',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c01_0',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c05_1',\n",
       " 'c00_1',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c03_0',\n",
       " 'c04_1',\n",
       " 'c00_0',\n",
       " 'c05_1',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c00_0',\n",
       " 'c02_0',\n",
       " 'c03_0',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c00_0',\n",
       " 'c04_0',\n",
       " 'c02_1',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c02_1',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c02_0',\n",
       " 'c03_0',\n",
       " 'c04_1',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c03_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c00_0',\n",
       " 'c04_1',\n",
       " 'c00_0',\n",
       " 'c05_1',\n",
       " 'c01_1',\n",
       " 'c03_1',\n",
       " 'c00_1',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c01_0',\n",
       " 'c02_1',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c05_1',\n",
       " 'c05_0',\n",
       " 'c01_1',\n",
       " 'c04_0',\n",
       " 'c02_1',\n",
       " 'c05_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c03_0',\n",
       " 'c03_1',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c03_0',\n",
       " 'c04_0',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c03_1',\n",
       " 'c05_1',\n",
       " 'c01_1',\n",
       " 'c02_0',\n",
       " 'c00_1',\n",
       " 'c01_1',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c02_0',\n",
       " 'c00_0',\n",
       " 'c05_0',\n",
       " 'c04_1',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c04_0',\n",
       " 'c01_0',\n",
       " 'c04_0',\n",
       " 'c00_1',\n",
       " 'c00_0',\n",
       " 'c01_1',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c04_1',\n",
       " 'c00_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c01_0',\n",
       " 'c03_1',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c04_1',\n",
       " 'c04_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c04_0',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c00_1',\n",
       " 'c02_0',\n",
       " 'c05_1',\n",
       " 'c00_1',\n",
       " 'c05_0',\n",
       " 'c03_1',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c02_1',\n",
       " 'c03_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c00_1',\n",
       " 'c03_0',\n",
       " 'c05_0',\n",
       " 'c05_1',\n",
       " 'c01_1',\n",
       " 'c00_1',\n",
       " 'c03_1',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c04_1',\n",
       " 'c00_1',\n",
       " 'c01_0',\n",
       " 'c05_0',\n",
       " 'c00_0',\n",
       " 'c00_1',\n",
       " 'c04_0',\n",
       " 'c04_0',\n",
       " 'c03_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c01_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c04_0',\n",
       " 'c04_1',\n",
       " 'c03_1',\n",
       " 'c03_1',\n",
       " 'c01_1',\n",
       " 'c04_1',\n",
       " 'c05_0',\n",
       " 'c02_0',\n",
       " 'c02_0',\n",
       " 'c03_1',\n",
       " 'c00_0',\n",
       " 'c00_1',\n",
       " 'c02_1',\n",
       " 'c02_0',\n",
       " 'c05_0',\n",
       " 'c05_0',\n",
       " 'c01_0',\n",
       " ...]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrsc.ccat_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83affe6-a2b4-4130-bab6-8351faa00ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
